---
layout: default
title: Let Me Guess What You Know  
subtitle: Measuring Demonstrated Potential Domain Knowledge with Knowledge Graphs
paperlink: http://ceur-ws.org/Vol-1883/paper_11.pdf
categories: research
excerpt: "
The Web consists of billions of pages providing useful information to solve many of
our day-to-day problems. During a single lifetime, however, we are able to process
only a limited fraction of these pages, carefully selecting the data that we do
process becomes important.  Search engines and recommender systems help us to
effectively select a small set of Web pages that potentially contain information
relevant to the queries we issue. What current search engines DO NOT consider is the
knowledge we may already have, or whether we are able to understand the information
presented.  In this post I am going to describe a recent study, including:
(1) A method we propose to measure demonstrated potential domain knowledge as a proxy for
knowledge; 
(2) How we use this metric to analyse the query log of a person spanning over 10 years;
and (3) How YOU can use the tools and resources to analyse your own search history. 
" 
---
<div id="top"></div>
# Measuring Demonstrated Potential Domain Knowledge with Knowledge Graphs  
<hr/>
<a class="notes" href="http://ceur-ws.org/Vol-1883/paper_11.pdf">Read the paper instead &rarr;</a>

[Motivation](#motivation)  
[Method](#method)  
[Demonstration](#demonstration)  
[Limitations and Next step](#next)  
[Resources and HowTo](#tools)  
[References](#references)


## <a id="motivation" name="motivation"></a> Motivation  
**Topical relevance vs. cognitive relevance**  

One of the main challenges for information systems (e.g. search and recommendation
systems) is to "guess" the intention of a user. That is, what the user is looking for
and what the user wants to see. Typically, "documents" (Web pages or or media types)
are selected based on _topical relevance_ --- to what extent a document is about the
query issued by the user, as well as contextual information such as age, location,
and search history of the user. 

From the user perspective, however, when seeking information to solve a task at hand,
the cognitive relevance of information presented depends on the individual user's
current knowledge of, and assumptions about, the world.  

These factors become especially relevant in situations where an information need goes
beyond simple fact lookup, and a user is trying to master a new skill or learn about
new topics.  For example, an individual who has not studied mathematics beyond
elementary arithmetic would not be capable of, or have great difficulty with,
processing information dealing with concepts of integral calculus [\[6\]](#references).  Meanwhile,
information about the topic that one has already mastered would not contribute much
to his/her problem solving effort.    

Contrary to topical
relevance, the cognitive relevance of information to a user's information need is
adapted to the users context, i.e., the user's knowledge of the world at a particular
point in time. A consequence is that it is constantly changing as by processing new
information a user's knowledge about the world may have changed.  

**Two components**  
The question is then, how to determine a user's knowledge? We argue that any such
effort requires at least two components: _expressions of a user's knowledge_ and a
_knowledge base_. 

**_a. Expressions of a user's knowledge:_**   
From work on the analysis of long term query logs we know that based
on users’ queries, changes in interest can be detected. For example, the query
"mortgage" was found to be correlated with "calculator" and "lender" within a 30
minute session. In a window between one and seven days, however, this changed to
terms such as "property." From one week to a month users used terms
such as "insurance," "notary and IRS." Finally, between one and three months
queries related to furnishing become more prevalent, e.g., "Bed Bath and Beyond" and
"Pottery Barn" [\[7\]](#references). So if a sufficiently comprehensive log of a user's queries can be
found, then this may allow us to gain insights in a user's knowledge. 

**_b. A knowledge base:_**  
Search logs alone, however, are not enough. They may be able to provide an overview of what a
user does know, but it does not provide any information about what is unknown to the
user, i.e., what a user could potentially learn about a particular topic. Knowledge
bases are (often) manually constructed repositories aimed at providing an overview of
the concepts that exist in a particular domain. These repositories could be seen as a
representation of the knowledge of an expert in the domain.



## <a name="method" id="method"></a>Proposed method 
**Defining Knowledge.**  

The definition of knowledge has been the topic of debate among scholars and
philosophers since at least the ancient Greek times and is generally known as a
branch of philosophy called epistemology. The work of the Greek philosopher Plato
gave rise to an early definition of knowledge as "justifiable true belief" (JTB):
* __Belief__: something that is known must have been
encountered, whether it is through perception or derivation. 
* __True__: the proposition,
fact, or object that is believed must be true in order to be known. 
* __Justifiable__:
there must be a reason, explanation, or account that explains why someone holds a
belief and believes that it is true. 

This notion of justifiable true belief has a central place in epistemology
[\[5\]](#references).  

More recent critics have suggested cases where a definition of knowledge as a justifiable
true belief fails, often referred to as Gettier problems or generalizations thereof
[\[4\]](#references). For example, the “cow in the field” problem, where a farmer checking up on his
cow confuses a piece of black and white canvas caught up in a distant bush for a cow.
However, since the animal actually is in the field, but lying hidden in a ditch the
farmer has a justified, true belief, which does not seem to qualify as “knowledge”
[\[2\]](#references). Others have suggested modifications to the theory of justified true beliefs by
adding additional constraints or modifying the definition of justification to render
such examples false.  

In this study we focus on two necessary conditions for justified true belief: 
__truth__ and __belief__. 

__Measuring Knowledge.__  

__Truth__. One component in our discussion above is truth: the
objects or facts that exist and can be known.  Aristotle described one of the first
ontologies that provides a high level categorization of the things there are
[\[3\]](#references).
With the rise of the Semantic Web and Linking Open Data Cloud, an ever increasing
ontology or _knowledge base_ (KB) is available that provides a reference for the facts and
objects that exist in the world and a representation of the things in the world that
someone can have knowledge about. 


__Belief__. The second component is belief: in order to know an object someone should have a
belief about that object. However, it is difficult to observe one's beliefs directly.
Instead we can observe beliefs as expressed through interactions with digital
systems, where users type queries, click on articles, and write messages. These
expressions may serve as observable expressions of beliefs. 


__Truth & Belief__. The final step is then to take the intersection between the truth
(things existing in the world) and the user's beliefs. Recent advances in query
understanding and entity recognition have resulted in systems that are able to
reliably link user expressions with objects in KBs [\[1\]](#references). For example, a
user issuing the query “Michael Schumacher” could link this expression to the entry
of Michael Schumacher the race car driver, derive related information from the
assertions in the Knowledge Base. This expression suggests that this user potentially
knows who Michael Schumacher is and attempts to connect his belief with the truth
through querying.

__Assumptions__.
Having set the scene with the above definitions, we now explore quantities and their
associated assumptions that can be used as metrics to operationalize the measurement
of knowledge.

1. First, if we accept that the collective justifiable true beliefs (JTBs) held by
a person constitute his/her knowledge, then counting the number of JTBs is a metric
of __*knowledge*__.

2. However, we already relaxed the requirement for justification and only focus on
counting true beliefs (TBs). Under this condition, if we assume that all beliefs of a
user are observed as expressions and that all these expression are perfectly
connected to an exhaustive Knowledge Base of things, then we measure the __*potential
set of knowledge*__ (TBs), where a user's actual knowledge will be the subset of these
that are justifiable (JTBs). 


3. Since no KB is complete, but if we assume that all beliefs of a user are observed
and those that appear in the KB are successfully connected as true beliefs then we
measure the user's __*potential knowledge within a certain domain*__ as specified by
the KB. 

4. Even if we observe all expressions of a user in digital systems during
his/her lifetime, not all of the user's beliefs will be observed. If both the observed
beliefs and the KB are incomplete then we measure the _potential observable beliefs of
a user within a particular domain_: one might call this __*"demonstrated/observed
potential domain knowledge" (DPDK)*__. 

5. The process of linking between observed
expressions of beliefs and KBs is also not perfect. However, we treat this as
measurement error.

Finally a note on __*forgetting*__. In the above argument we assume that the TBs of a
person always increase as he/she acquires new information. We therefore treat
forgetting as no longer being able to provide a justification for a belief. This
seems reasonable since having observed that the belief was once held makes it a
potential JTB and thus potential knowledge. We leave the handling of forgetting for
future work.

## <a id="demonstration" name="demonstration"></a>The query log of a person over 10 years

__Experiment Setup__

We now demonstrate how we use the metric defined above to measure the demonstrated
potential domain knowledge (DPDK).

__*Knowledge base:*__
As our reference knowledge base of things that exist in the world we use DBpedia.
DBpedia as a knowledge base extracted from Wikipedia and contains encyclopedic
knowledge in the order of 580 million facts (relations) about 4.5 million objects
(entities). 

__*Expressions of beliefs:*__
In order to obtain expressions of beliefs we obtained the Google search query log of
one of the authors from https://takeout.google.com/settings/takeout. The log ranges
from Jan 2007 to Dec 2016 and contains about 62K queries.

__*Linking expressions of beliefs to KB:*__
To link expressions of belief, i.e., queries, to the knowledge base we use a state of
the art open source entity linking tool released by Yahoo! [\[1\]](#references). The linking tool
assign a score to a query-entity pair indicating the log-likelihood of the two are
associated.  If a query is successfully linked to one or more entities we select the
entity with the highest log-likelihood score with a minimal score threshold of -3.0.
Using this procedure we link 39K queries to the knowledge base.
We observe that about 60 to 70 percent of the queries are consistently linked to an
entity over time. 

__Quantative analysis__

We compute the following metrics to measture a person's demonstrated potential
domain knowledge (DPDK).

__*Knowledge: the cumulative number of unique entities expressed per month.*__
The entities are unique since only the first occurrence of an entity is considered.
This reflects the intuition that multiple expression of the same knowledge do not
increase the overall DPDK. 

We see from [Figure 1a](#figure1) that the cumulative number of queries and the cumulative number
of entities follow a similar curve.  In [Figure 1b](#figure1), however, when only the first
occurrence of a query/entity is considered, we no longer observe similar trends. The
unique cumulative entities now exhibit a linear relationship over time. 


<div id="figure1"></div>

![](/assets/img/kg4ir/monthly_cq_vs_ce.pdf)| ![](/assets/img/kg4ir/monthly_ucq_vs_uce.pdf) 
[Figure 1a. the cumulative number of queries (darkgray) and entities (lightgray) each month](/assets/img/kg4ir/monthly_cq_vs_ce.pdf) | [Figure 1b. The cumulative number of unique queries / entities (first occurrence of a query only).](/assets/img/kg4ir/monthly_ucq_vs_uce.pdf)

So why is this contrast observation interesting? This is an interesting finding for
two reasons:

First, we
observe that a metric based on queries and a metric based on entities measure
different things. It suggests that the step of linking queries (or expressions of
beliefs) to a knowledge base succeeds in differentiating between searching for
information and expressing beliefs about facts in a domain. 

Second, it suggests that
over 10 years time the author sought out new knowledge at roughly the same rate. It
would be interesting to investigate whether this pattern generalizes to a wider
sample and whether it correlates with curiosity or a personality traits.

__*Knowledge-velocity: the first derivative of DPDK.*__ 
Monthly view shown in [Figure 2a](#figure2). 

__*Knwoledge-acceleration: the second derivative of DPDK.*__ 
Monthly view shown in [Figure 2b](#figure2).

<div id="figure2"></div>

![](/assets/img/kg4ir/monthly_gucq_vs_guce.pdf)|![](/assets/img/kg4ir/monthly_2gucq_vs_2guce.pdf) 
[Figure 2a. DPDK-velocity at each point (month) of the cumulative number of unique queries (darkgray) and entities (lightgray).](/assets/img/kg4ir/monthly_cq_vs_ce.pdf) | [Figure 2b. DPDK-acceleration at each point (month) of the cumulative number of unique queries / entities.  Query stats skipped for clarity.](/assets/img/kg4ir/monthly_ucq_vs_uce.pdf)

We observe that the number of unique queries per month has high variance.
In contrast the number of unique entities per month is more stable, with
one exception around month 25. This is more clearly visible in the right graph that
shows the second derivative at each point of the cumulative unique entities (for
clarity the analogous data for queries is not shown). The author suspects this spike
is due to finishing a MSc thesis followed by a long holiday.


__*Summary.*__
This part shows that using unique entities as a basis for measuring beliefs is
different from using queries. It suggests that query volume is not necessarily driven
by quests for new knowledge but also by re-finding or perhaps knowledge outside of
the domain of Wikipedia. We have not touched on what kind of potential knowledge was
expressed by the author (user). We look into this next with qualitative analysis.


__Qualitative analysis__ 

The above analysis treats all expressions that are linked to the knowledge base as
observed expressions of beliefs about the domain of the knowledge base. It is not
uncommon, however, for sub-domains to exist within a knowledge base, especially one
as broad as DBPedia.  People, then, may express beliefs about a diverse set of
domains during a particular time, or such expressions could be focussed on a
particular domain. 

To analyse whether we observe such behaviour in the author's log, we utilize the
DBPedia categories, representing different domains, to cluster queries that are
linked to entities within the same category in the knowledge base. 

The Wikipedia category structure is not a strict hierarchy. To assign each entity to
a single category at a particular level in the category structure we extract a
hierarchy from the category structure. We use
[Category:Main\_topic\_classifications](https://en.wikipedia.org/wiki/Category:Main_topic_classifications)
as the root node of the category hierarchy, eliminate cycles, and pick the shortest
one to the root when multiple paths exist. 

Given this hierarchy, we find for each entity all its categories and the shortest
path to the root. We can then slice the hierarchy at a particular level and find for
each category all the entities that are associated with it. The amounts of identified
entities covered under different categories can be seen as a distribution of a user's
potential domain knowledge. 

One way to use this distribution, for instance, is to compare the knowledge
distribution between different people, e.g. experts vs. novices. Since we lack the
logs of multiple people, here we inspect changes in potential domain knowledge within
the same log year over year.

__*The author's DPDK visualised year-by-year*__


[Figure 3](#figure3) shows the concepts linked from queries issued within a particular year as
vertices in red and concepts linked from queries issued within other years as
vertices in blue. Edges represent has category relations and clusters are formed by
concepts that are all of the same category. The central vertex in each cluster is the
category name. 

The visualization was created using the open source tool
[Gephi3](https://gephi.org) and enables exploration of how the number of concepts a
users potentially knows increases over time. For clarity we only show the names of
the categories with the highest acceleration of concepts linked from expressions
during a year in a particular domain.

<div id="figure3"></div>

![](/assets/img/kg4ir/2012_2013_known_vs_unknown_final_brigthter.png)|![](/assets/img/kg4ir/2013_2014_known_vs_unknown_final_brigthter.png)
2012-2013 | 2013-2014
![](/assets/img/kg4ir/2014_2015_known_vs_unknown_final_brigthter.png)|![](/assets/img/kg4ir/2015_2016_known_vs_unknown_final_brigthter.png)
2014-2015 | 2015-2016

<br/>

__*The author's reflection on the visualised search history*__ 

**2012-2013:** 
We observe that in 2012-2013 most expressions were linked to the category
"Probability and Statistics." These queries were issued during the author's time as a
PhD student in Information Retrieval. The author suspects that this may have prompted
an increase in queries related to that category. 

**2013-2014:** 
In 2013-2014, after just finishing up as a PhD, the author was teaching a course on
Social Network Analysis to undergraduate students and suspects that is the cause of
an increase in the proportion of queries related to the category "Graph Theory".

**2014-2015:** 
In 2014-2015 it is more difficult to single out a category in which new knowledge was
demonstrated, but the author noted that the rise in queries related to the category
"Marriage" corresponds well with an life event during that year: getting married.

**2015-2016:** 
The visualization of 2015-2016 shows a number of interesting categories “Human
Reproduction”, “Fertility”, and “Tissues (Biology)” as well as “Governance in the
United Kingdom and Taxation.” These categories again align with some of the author's
life events during that year, i.e,. expecting the first child and moving to the United
Kingdom.

__*Summary.*__
The kind of qualitative analysis of a query log, like the one above, would be very
difficult for anyone but the one who issued the queries. Even then it is hard to know
what prompted an acceleration in queries related to concepts in a particular domain.
What we do observe is that such accelerations can be explained by the occurrence of
certain life events. An interesting direction for future work would be to analyse how
accelerations observed at different (lower) levels of the hierarchy, i.e., more
specialized domains, relate to events in users' lives.


## <a id="next" name="next"></a>Limitations and Next step 
Like all studies, there are limitations of the study I just described. 
We note that this study is exploratory in nature and understand
the lack of generalizability of our findings beyond the log used in the study.
However, we believe that our findings will motivate further study into this topic.

The choice to use a single log in our analysis was made for several reasons: 
* Practical: it is hard to obtain a large sample of long term (e.g.,
over a decade) user logs. 
* Reliability: it is difficult for an external assessor to judge
what motivated users to issue particular queries --- therefore we took one of the
authors' own log. 
* Ethical: 
in our qualitative analysis we aim to understand the actions and motivations of the
user over an extended period of their life and such an analysis 
requires user consent. 

To fully examine the validity of our hypotheses and the effectiveness of our proposed metrics,
further experiments are needed.  

**_If you are interested in participating this experiment as a volunteer, please let me
know!_**


## <a id="tools" name="tools"></a>Resources, tools, and HowTo
Get your own [query history](https://takeout.google.com/settings/takeout)
from Google.

Tool for linking queries with Wikipedia concepts: 
[Yahoo! Fast Entity Linker](https://github.com/yahoo/FEL)

I just realised that the post is getting very long, and decided
to write up the [How To part]() in a new post.   


## <a name="references"></a>References
1. R. Blanco, G. Ottaviano, and E. Meij.
Fast and space-efficient entity linking for queries.
_In Proceedings of the Eighth ACM International
Conference on Web Search and Data Mining_, pages 179–188. ACM, 2015.
2. M. Cohen. _101 philosophy problems_. Routledge, 2013.
3. S. M. Cohen. _Aristotle's metaphysics_. 2000.
4. E. L. Gettier. Is justified true belief knowledge? _Analysis_, 23(6):121–123, 1963.
5. A. I. Goldman. What is justified belief? In _Justification and knowledge_, pages
1–23. Springer, 1979.
6. S. P. Harter.
Psychological relevance and information science.
_Journal of the American Society for information Science_, 43(9):602,1992.
7. M. Richardson.
Learning about the world through long-term query logs.
_ACM Transactions on the Web(TWEB)_, 2(4):21,2008.
8. A. Silverman. _Plato's middle period metaphysics and epistemology_. 2003.
9. A. Spink, H. Greisdorf, and J.Bateman.
From highly relevant to not relevant: examining different regions of relevance.
_Information Processing & Management_, 34(5):599–621, 1998.

[back to top](#top)

